import pandas as pd
import numpy as np
import geopandas as gpd
import osmnx as ox
import h3
import optuna
from sklearn.model_selection import train_test_split, KFold
from sklearn.neighbors import BallTree
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import os
from tqdm import tqdm
import warnings

# ì„¤ì •
warnings.filterwarnings('ignore')
optuna.logging.set_verbosity(optuna.logging.WARNING)
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
except:
    plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False


# ğŸ’¡ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ ì‹œê°í™” í•¨ìˆ˜ 
def plot_actual_vs_predicted(y_test, pred_log, mae):
    """
    ì‹¤ì œê°’(y_test)ê³¼ ì˜ˆì¸¡ê°’(pred_log)ì„ ë¹„êµí•˜ê³  ì”ì°¨ë¥¼ ë¶„ì„í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ë¡œê·¸ ìŠ¤ì¼€ì¼ í•´ì œí•˜ì—¬ ì‹¤ì œ ê°œìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°í™”)
    """
    # ë¡œê·¸ ë³€í™˜ í•´ì œ (np.expm1 ì‚¬ìš©)
    y_real = np.expm1(y_test)
    # ì˜ˆì¸¡ê°’ì´ 0ë³´ë‹¤ ì‘ì€ ê²½ìš°ë¥¼ ë°©ì§€ (ë¡œê·¸ ë³€í™˜ì˜ ì—­ë³€í™˜ì´ë¯€ë¡œ)
    pred_real = np.expm1(np.maximum(0, pred_log)) 

    residuals = pred_real - y_real 

    fig, axes = plt.subplots(1, 2, figsize=(18, 7))
    plt.suptitle("Model Evaluation: Actual vs. Predicted & Residual Analysis", fontsize=18)

    # 1. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ 
    axes[0].scatter(y_real, pred_real, alpha=0.6, color='#5DADE2', edgecolors='w', linewidths=0.5)

    # ì™„ë²½í•œ ì˜ˆì¸¡ì„ 
    max_val = max(y_real.max(), pred_real.max())
    min_val = min(y_real.min(), pred_real.min())
    axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction (y=x)')

    axes[0].set_title(f"1. Actual vs. Predicted Towing Count (MAE: {mae:.2f})", fontsize=15)
    axes[0].set_xlabel("Actual Towing Count ", fontsize=13)
    axes[0].set_ylabel("Predicted Towing Count ", fontsize=13)
    axes[0].grid(True, linestyle='--', alpha=0.6)
    axes[0].legend()

    # 2. ì”ì°¨ í”Œë¡¯ (Residual Plot) 
    axes[1].scatter(y_real, residuals, alpha=0.6, color='#A569BD', edgecolors='w', linewidths=0.5)
    axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2) # ì”ì°¨ê°€ 0ì¸ ê¸°ì¤€ì„ 
    
    axes[1].set_title("2. Residual Plot", fontsize=15)
    axes[1].set_xlabel("Actual Towing Count", fontsize=13)
    axes[1].set_ylabel("Residuals (Predicted - Actual)", fontsize=13)
    axes[1].grid(True, linestyle='--', alpha=0.6)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()


class TowingHotspotPredictor:
    """
    Random Forestì™€ Optunaë¥¼ ì´ìš©í•œ ì „ë™ í‚¥ë³´ë“œ ê²¬ì¸ í•«ìŠ¤íŒŸ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸.
    """
    def __init__(self, data_path, resolution=10, cache_folder='cache'):
        self.data_path = data_path
        self.resolution = resolution
        self.cache_folder = cache_folder
        os.makedirs(self.cache_folder, exist_ok=True)
        self.poi_data = {}
        self.features = []
        self.df_modeling = pd.DataFrame()
        self.target_log = pd.Series(dtype=float)
        self.best_model = None
        self.raw_data = None
        self.road_graph = None
        self.road_edges_gdf = gpd.GeoDataFrame()
        self.X_train = pd.DataFrame()
        self.y_train = pd.Series(dtype=float)
        self.feature_importance_series = pd.Series(dtype=float)

    def load_data(self):
        """[1ë‹¨ê³„] ë°ì´í„° ë¡œë”© ë° ì´ìƒì¹˜(ê°•ë‚¨êµ¬) ì œê±°."""
        print(f"ğŸ”¹ [1ë‹¨ê³„] ê²¬ì¸ ì›ë³¸ ë°ì´í„° ë¡œë“œ...")
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_path}")

        df_loaded = None

        try:
            df_loaded = pd.read_excel(self.data_path)
            print(f" Â  Â -> âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ (pd.read_excel ì‚¬ìš©)")
        except Exception:
            try:
                df_loaded = pd.read_csv(self.data_path, encoding='cp949')
                print(f" Â  Â -> âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ (pd.read_csv, ì¸ì½”ë”©: cp949ë¡œ ëŒ€ì²´)")
            except UnicodeDecodeError:
                try:
                    df_loaded = pd.read_csv(self.data_path, encoding='cp949', errors='replace')
                    print(f" Â  Â -> âš ï¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ (cp949 + errors='replace'ë¡œ ì˜¤ë¥˜ ë¬¸ì ëŒ€ì²´ ë° ê°•ì œ ë¡œë“œ)")
                except Exception as e_final:
                    raise Exception(f"íŒŒì¼ ë¡œë“œ ìµœì¢… ì‹¤íŒ¨ (Excel/CSV ì˜¤ë¥˜): {e_final}")

        if df_loaded is None:
            raise Exception("íŒŒì¼ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.raw_data = df_loaded

        self.raw_data = self.raw_data.dropna(subset=['lat', 'lng'])
        self.raw_data['lat'] = pd.to_numeric(self.raw_data['lat'])
        self.raw_data['lng'] = pd.to_numeric(self.raw_data['lng'])

        if 'êµ¬ì •ë³´' in self.raw_data.columns:
            org_len = len(self.raw_data)
            self.raw_data = self.raw_data[self.raw_data['êµ¬ì •ë³´'] != 'ê°•ë‚¨êµ¬']
            print(f" Â  Â -> ê°•ë‚¨êµ¬ ë°ì´í„° ì œì™¸ ì™„ë£Œ ({org_len:,d} -> {len(self.raw_data):,d}ê±´)")
        else:
            print(" Â  Â -> 'êµ¬ì •ë³´' ì»¬ëŸ¼ì´ ì—†ì–´ ê°•ë‚¨êµ¬ ì œì™¸ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")


    def load_environmental_data(self):
        """[2ë‹¨ê³„] í™˜ê²½ ë°ì´í„°(POI, ë„ë¡œë§) ë¡œë“œ/ë‹¤ìš´ë¡œë“œ."""
        print("ğŸ”¹ [2ë‹¨ê³„] ì£¼ë³€ í™˜ê²½ ë°ì´í„°(POI) ë° ë„ë¡œë§ ë¡œë“œ...")

        poi_tags = {
            'subway': {'railway': 'station', 'station': 'subway'},
            'bus': {'highway': 'bus_stop'},
            'school': {'amenity': 'school'},
            'crosswalk': {'highway': 'crossing'},
            'cafe': {'amenity': 'cafe'}
        }

        def fetch_poi(name, tag):
            cache_file = os.path.join(self.cache_folder, f"seoul_{name}.geojson")
            if os.path.exists(cache_file):
                try: return gpd.read_file(cache_file)
                except Exception: pass

            try:
                gdf = ox.features_from_place("Seoul, South Korea", tags=tag)
                if gdf.empty or 'geometry' not in gdf.columns: return gpd.GeoDataFrame(geometry=[])

                gdf = gdf[gdf.geometry.type.isin(['Point', 'LineString', 'MultiPoint', 'Polygon'])]
                if not gdf.empty:
                    gdf['geometry'] = gdf.geometry.apply(lambda g: g.centroid if g.geom_type != 'Point' else g)
                    gdf = gdf[['geometry']].copy()
                    gdf.to_file(cache_file, driver='GeoJSON', encoding='utf-8')
                return gdf
            except Exception:
                return gpd.GeoDataFrame(geometry=[])

        for name, tag in poi_tags.items():
            self.poi_data[name] = fetch_poi(name, tag)

        road_file = os.path.join(self.cache_folder, 'seoul_roads_drive.graphml')
        if os.path.exists(road_file):
            self.road_graph = ox.load_graphml(road_file)
        else:
            print(" Â  Â -> âš ï¸ ë„ë¡œë§ ë‹¤ìš´ë¡œë“œ ì¤‘ (ì‹œê°„ ì†Œìš”)...")
            try:
                self.road_graph = ox.graph_from_place("Seoul, South Korea", network_type='drive')
                ox.save_graphml(self.road_graph, road_file)
            except Exception:
                self.road_graph = None

        if self.road_graph:
            self.road_edges_gdf = ox.graph_to_gdfs(self.road_graph, nodes=False, edges=True)
        else:
            self.road_edges_gdf = gpd.GeoDataFrame()


    def create_features(self):
        """[3ë‹¨ê³„] H3 ê²©ì ê¸°ë°˜ì˜ ê³µê°„ íŠ¹ì§•(Feature) ê³µí•™."""
        print(f"ğŸ”¹ [3ë‹¨ê³„] H3 ê²©ì ë§¤í•‘ ë° ë³µí•© íŠ¹ì§• ìƒì„± (res={self.resolution})...")

        if self.raw_data is None or self.raw_data.empty:
            raise Exception("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        self.raw_data['h3'] = self.raw_data.apply(
            lambda x: h3.latlng_to_cell(x['lat'], x['lng'], self.resolution),
            axis=1
        )

        target_df = self.raw_data['h3'].value_counts().reset_index()
        target_df.columns = ['h3', 'count']
        target_df['y_log'] = np.log1p(target_df['count'])
        hex_list = target_df['h3'].tolist()

        def calculate_road_density(hex_list, edges, res):
            if edges.empty: return [0.0] * len(hex_list)

            edges['h3'] = edges.geometry.centroid.apply(lambda g: h3.latlng_to_cell(g.y, g.x, res))
            if 'length' in edges.columns:
                length_by_hex = edges.groupby('h3')['length'].sum().to_dict()
            else:
                try: length_by_hex = edges.geometry.length.groupby(edges['h3']).sum().to_dict()
                except Exception: return [0.0] * len(hex_list)
            return [length_by_hex.get(h, 0.0) for h in hex_list]

        def calculate_nearest_distance(hex_list, target_gdf):
            if target_gdf.empty or len(target_gdf) == 0: return [999999.0] * len(hex_list)
            coords = [h3.cell_to_latlng(h) for h in hex_list]
            src = np.radians(np.array(coords))
            point_geoms = target_gdf.geometry[target_gdf.geometry.type == 'Point']
            if point_geoms.empty: return [999999.0] * len(hex_list)
            tgt = np.radians(np.array([(p.y, p.x) for p in point_geoms]))
            tree = BallTree(tgt, metric='haversine')
            dists, _ = tree.query(src, k=1)
            return (dists.flatten() * 6371000).tolist() 

        def calculate_poi_influence(hex_list, target_gdf, res, decay=0.5):
            if target_gdf.empty or len(target_gdf) == 0: return [0.0] * len(hex_list)
            p_h3 = [h3.latlng_to_cell(geom.y, geom.x, res) for geom in target_gdf.geometry if geom.geom_type == 'Point']
            if not p_h3: return [0.0] * len(hex_list)
            p_cnt = pd.Series(p_h3).value_counts().to_dict()
            res_list = []
            for h in hex_list:
                s = 0.0
                for n in h3.grid_disk(h, 1): 
                    c = p_cnt.get(n, 0)
                    if c > 0: s += c * (1.0 if n == h else decay)
                res_list.append(float(s))
            return res_list

        data = {
            'road_density': calculate_road_density(hex_list, self.road_edges_gdf, self.resolution),
            'dist_subway': calculate_nearest_distance(hex_list, self.poi_data['subway']),
            'dist_school': calculate_nearest_distance(hex_list, self.poi_data['school']),
            'dist_cross': calculate_nearest_distance(hex_list, self.poi_data['crosswalk']),
            'imp_cafe': calculate_poi_influence(hex_list, self.poi_data['cafe'], self.resolution, 0.5),
            'imp_bus': calculate_poi_influence(hex_list, self.poi_data['bus'], self.resolution, 0.3)
        }

        self.df_modeling = pd.DataFrame(data)
        self.target_log = target_df['y_log']
        self.features = list(data.keys())
        print(" Â  Â -> í”¼ì²˜ ìƒì„± ì™„ë£Œ:", self.features)


    def train_and_optimize(self, trials=10):
        """[4ë‹¨ê³„] Optuna ê¸°ë°˜ Random Forest ëª¨ë¸ ìµœì í™” ë° í•™ìŠµ"""
        print(f"\nğŸ”¹ [4ë‹¨ê³„] Optuna ìµœì í™” ë° Random Forest í•™ìŠµ (ì‹œë„ íšŸìˆ˜: {trials})...")

        if self.df_modeling.empty:
            raise Exception("ëª¨ë¸ í•™ìŠµ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        X_train, X_test, y_train, y_test = train_test_split(
            self.df_modeling, self.target_log, test_size=0.2, random_state=42
        )
        self.X_train = X_train
        self.y_train = y_train

        def objective(trial):
            param = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 5, 20),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                'max_features': trial.suggest_float('max_features', 0.6, 1.0),
                'n_jobs': -1,
                'random_state': 42
            }
            model = RandomForestRegressor(**param)
            kf = KFold(n_splits=3, shuffle=True, random_state=42)
            # êµì°¨ ê²€ì¦
            scores = [r2_score(y_train.iloc[val], model.fit(X_train.iloc[tr], y_train.iloc[tr]).predict(X_train.iloc[val]))
                      for tr, val in kf.split(X_train, y_train)]
            return np.mean(scores)

        # Optuna
        try:
            study = optuna.create_study(direction='maximize')
            study.optimize(objective, n_trials=trials, show_progress_bar=True)
            print(f" Â  Â ğŸ” ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°: {study.best_params}")
            best_params = study.best_params
        except Exception as e:
            print(f"Optuna ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ ({e}). ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            best_params = {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 10,
                'min_samples_leaf': 5,
                'max_features': 1.0
            }


        self.best_model = RandomForestRegressor(
            **best_params, n_jobs=-1, random_state=42
        )
        self.best_model.fit(X_train, y_train)

        r2 = self.best_model.score(X_test, y_test)
        pred_log = self.best_model.predict(X_test)

        pred_real = np.expm1(np.maximum(0, pred_log))
        y_real = np.expm1(y_test)
        mae = mean_absolute_error(y_real, pred_real)

        print("\n" + "="*50)
        print(f"ğŸ† ìµœì¢… ëª¨ë¸ í™•ì • ì„±ì í‘œ (ëª¨ë¸: RandomForest, R={self.resolution})")
        print(f"âœ… R2 Score (í…ŒìŠ¤íŠ¸): {r2:.4f}")
        print(f"âœ… MAE (í‰ê·  ì˜¤ì°¨): {mae:.2f}ê±´")
        print("="*50)

        r2_train = self.best_model.score(X_train, y_train)
        r2_test = r2
        r2_diff = r2_train - r2_test

        if r2_train > 0:
            overfit_ratio = (r2_diff / r2_train) * 100
        else:
            overfit_ratio = 100.0

        print("\n--- ëª¨ë¸ ì í•©ë„ ì§„ë‹¨ ---")
        print(f"R2 í›ˆë ¨ ì„±ëŠ¥ (Training): {r2_train:.4f}")
        print(f"R2 í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ (Testing): {r2_test:.4f}")
        print(f"R2 ì°¨ì´ (Gap): {r2_diff:.4f}")
        print(f"âš ï¸ ê³¼ì í•© ë¹„ìœ¨ (% ì†ì‹¤): {overfit_ratio:.2f}%")

        if r2_diff > 0.05:
            fit_status = "âš ï¸ Overfitting (ê³¼ì í•©) ê²½í–¥"
        elif r2_test < 0.2:
            fit_status = "âŒ Poor Fit / Underfit (íŒ¨í„´ì„ ì¶©ë¶„íˆ í•™ìŠµí•˜ì§€ ëª»í•¨)"
        else:
            fit_status = "âœ… Good Fit (ì ì ˆí•œ ì¼ë°˜í™”)"

        print(f"ì í•©ë„ íŒì •: {fit_status}")
        print("--------------------")

        plot_actual_vs_predicted(y_test, pred_log, mae)

        imp = pd.Series(
            self.best_model.feature_importances_,
            index=self.features
        ).sort_values(ascending=False)
        self.feature_importance_series = imp
        print("\nğŸ” ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance):\n", imp.to_string())

        return self.best_model


def plot_results(model_instance):
    """ê²°ê³¼ ì‹œê°í™” (ë³€ìˆ˜ ì¤‘ìš”ë„ ë§‰ëŒ€ ê·¸ë˜í”„)"""
    plt.figure(figsize=(10, 6))
    model_instance.feature_importance_series.plot(kind='barh', color='skyblue')
    plt.title('Feature Importance', fontsize=15)
    plt.xlabel('Importance Score', fontsize=12)
    plt.ylabel('Feature', fontsize=12)
    plt.gca().invert_yaxis()
    plt.show()
    pass


if __name__ == "__main__":
    data_file = 'ì„œìš¸ì‹œ_ì „ë™í‚¥ë³´ë“œ_ê²¬ì¸í˜„í™©_ì¢Œí‘œ_ê²°ì¸¡ì¹˜ì œê±°(21.7~25.6).xlsx'

    try:
        pipeline = TowingHotspotPredictor(data_file)

        print("----------------------------------------------------")
        print(" Â  Â  Â  Â  Â  Â  Towing Hotspot ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰ ì‹œì‘ Â  Â  Â  Â  Â  Â  ")
        print("----------------------------------------------------")

        pipeline.load_data()
        pipeline.load_environmental_data()
        pipeline.create_features()
        best_model = pipeline.train_and_optimize(trials=10) 

        plot_results(pipeline)

    except FileNotFoundError as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. {e}")
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
